{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 9054591,
     "sourceType": "datasetVersion",
     "datasetId": 5459691
    },
    {
     "sourceId": 84200,
     "sourceType": "modelInstanceVersion",
     "modelInstanceId": 70727,
     "modelId": 95769
    },
    {
     "sourceId": 84288,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 70805,
     "modelId": 95821
    }
   ],
   "dockerImageVersionId": 30747,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Model training done on kaggle notebook with GPU T4 x2.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install tensorflow\n!pip install matplotlib\n!pip install wurlitzer\n!pip install scikit-learn",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-07-29T02:13:13.925596Z",
     "iopub.execute_input": "2024-07-29T02:13:13.926039Z",
     "iopub.status.idle": "2024-07-29T02:14:20.157590Z",
     "shell.execute_reply.started": "2024-07-29T02:13:13.926001Z",
     "shell.execute_reply": "2024-07-29T02:14:20.155596Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m26.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\n\u001B[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed keras-2.15.0\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nCollecting wurlitzer\n  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\nDownloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\nInstalling collected packages: wurlitzer\nSuccessfully installed wurlitzer-3.1.1\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "import tensorflow as tf\nimport keras\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport numpy as np\nimport os",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:14:50.024917Z",
     "iopub.execute_input": "2024-07-29T02:14:50.025663Z",
     "iopub.status.idle": "2024-07-29T02:14:50.034016Z",
     "shell.execute_reply.started": "2024-07-29T02:14:50.025627Z",
     "shell.execute_reply": "2024-07-29T02:14:50.032467Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Check if GPU is available\nif tf.config.list_physical_devices('GPU'):\n    print(\"GPU is available\")\nelse:\n    print(\"GPU not available\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-28T23:19:06.313483Z",
     "iopub.execute_input": "2024-07-28T23:19:06.313847Z",
     "iopub.status.idle": "2024-07-28T23:19:06.514737Z",
     "shell.execute_reply.started": "2024-07-28T23:19:06.313817Z",
     "shell.execute_reply": "2024-07-28T23:19:06.513667Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "GPU is available\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "BATCH_SIZE = 64\nIMG_SIZE = (224, 224)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def load_data(train_dir, batch_size, img_size):\n    # Data augmentation for training data\n    train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        validation_split=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        rotation_range=30,\n        zoom_range=0.3,\n        width_shift_range=0.3,\n        height_shift_range=0.3,\n        brightness_range=[0.7, 1.3]\n    )\n\n    # Only rescale for validation data\n    val_datagen = ImageDataGenerator(\n        rescale=1./255,\n        validation_split=0.2\n    )\n\n    train_ds = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='training'\n    )\n\n    val_ds = val_datagen.flow_from_directory(\n        train_dir,\n        target_size=img_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        subset='validation'\n    )\n\n    return train_ds, val_ds",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_model(fine_tune_at=None):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    if fine_tune_at is not None:\n",
    "        base_model.trainable = True\n",
    "        # Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "    else:\n",
    "        base_model.trainable = False  # Initially, freeze the base model\n",
    "\n",
    "    # Correctly handle the output tensor from the base model\n",
    "    x = base_model.output\n",
    "    if isinstance(x, list):\n",
    "        print(\"It's a list\")\n",
    "        x = x[0]  # Take the first tensor if the output is a list\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    Add more layers if the data is very huge.\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)  # Additional dense layer with L2 regularization\n",
    "    x = Dropout(0.3)(x)  # Dropout to reduce overfitting\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    output = Dense(2, activation='softmax')(x)  # 2 output classes for binary classification\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_and_fine_tune_model(model, train_ds, val_ds):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint('/kaggle/working/bio_nonbio_model_best.keras', save_best_only=True, monitor='val_loss', mode='min', save_format='keras')\n",
    "    history = model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[early_stopping, checkpoint])\n",
    "   \n",
    "    return history"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def evaluate_model(model, test_ds):\n    loss, accuracy = model.evaluate(test_ds, verbose=2)\n    print(f\"Testing set Accuracy: {accuracy}\")\n    return accuracy",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def plot_history(history):\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n\n    plt.tight_layout()\n    plt.show()",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def compute_confusion_matrix(model, test_ds):\n    # Predict the values from the test dataset\n    predictions = model.predict(test_ds)\n    predicted_classes = np.argmax(predictions, axis=1)\n    true_classes = test_ds.classes\n    class_labels = list(test_ds.class_indices.keys())\n    \n    # Print classification report\n    print(\"Classification Report:\\n\", classification_report(true_classes, predicted_classes, target_names=class_labels))\n    \n    # Compute confusion matrix\n    cm = confusion_matrix(true_classes, predicted_classes)\n    print(\"Confusion Matrix:\\n\", cm)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "TRAIN_DIR = \"/kaggle/input/non-and-biodegradable-waste-dataset/TRAIN.1\"\n\ntrain_ds, val_ds = load_data(TRAIN_DIR, BATCH_SIZE, IMG_SIZE)\n\nfor i in (train_ds.class_indices):\n    print(i)\n\n# Fine-tuning the last 4 layers\nmodel = create_model(fine_tune_at=15)\nhistory = train_and_fine_tune_model(model, train_ds, val_ds)\nevaluate_model(model, val_ds)\nplot_history(history)\n\n# Compute and print confusion matrix\ncompute_confusion_matrix(model, val_ds)",
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# **Let's Test the Model**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(\"/kaggle/input/waste-classification-model/tensorflow2/default/1/bio_nonbio_model_best.keras\")\n",
    "\n",
    "# Let's see if the model loads by checking the summary\n",
    "print(model.summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:15:04.318281Z",
     "iopub.execute_input": "2024-07-29T02:15:04.318724Z",
     "iopub.status.idle": "2024-07-29T02:15:14.644334Z",
     "shell.execute_reply.started": "2024-07-29T02:15:04.318692Z",
     "shell.execute_reply": "2024-07-29T02:15:14.642782Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"model_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten_2 (Flatten)         (None, 25088)             0         \n                                                                 \n dense_2 (Dense)             (None, 2)                 50178     \n                                                                 \n=================================================================\nTotal params: 14764866 (56.32 MB)\nTrainable params: 7129602 (27.20 MB)\nNon-trainable params: 7635264 (29.13 MB)\n_________________________________________________________________\nNone\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Class labels\nclass_labels = [\"Biodegradable\", \"Non-Biodegradable\"]\n\ndef preprocess_image(img_path):\n    img = Image.open(img_path)\n    img = img.resize((224, 224))\n    img_array = image.img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    return img_array\n\n# Path to the image you want to predict\nimage_path = \"/kaggle/input/test-data/Tests/test9.jpeg\"\n\n# Preprocess the image\nimg_array = preprocess_image(image_path)\n\n# Make the prediction\npredictions = model.predict(img_array)\npredicted_class = np.argmax(predictions, axis=1)[0]\npredicted_label = class_labels[predicted_class]\nconfidence = predictions[0][predicted_class]\n\nprint(f\"Predicted class: {predicted_label}, Confidence: {confidence:.2f}\")\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:44:29.572024Z",
     "iopub.execute_input": "2024-07-29T02:44:29.572442Z",
     "iopub.status.idle": "2024-07-29T02:44:30.118910Z",
     "shell.execute_reply.started": "2024-07-29T02:44:29.572412Z",
     "shell.execute_reply": "2024-07-29T02:44:30.117754Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": "1/1 [==============================] - 0s 293ms/step\nPredicted class: Non-Biodegradable, Confidence: 1.00\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Let's convert to TensorFlow.js",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "!pip install tensorflowjs",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:15:33.748698Z",
     "iopub.execute_input": "2024-07-29T02:15:33.749210Z",
     "iopub.status.idle": "2024-07-29T02:15:58.363787Z",
     "shell.execute_reply.started": "2024-07-29T02:15:33.749170Z",
     "shell.execute_reply": "2024-07-29T02:15:58.362057Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting tensorflowjs\n  Downloading tensorflowjs-4.20.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: flax>=0.7.2 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (0.8.5)\nRequirement already satisfied: importlib_resources>=5.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (6.1.1)\nRequirement already satisfied: jax>=0.4.13 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (0.4.30)\nRequirement already satisfied: jaxlib>=0.4.13 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (0.4.30)\nRequirement already satisfied: tensorflow<3,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (2.15.0)\nRequirement already satisfied: tf-keras>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (2.15.1)\nRequirement already satisfied: tensorflow-decision-forests>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (1.8.1)\nRequirement already satisfied: six<2,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (1.16.0)\nRequirement already satisfied: tensorflow-hub>=0.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflowjs) (0.16.1)\nCollecting packaging~=23.1 (from tensorflowjs)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (1.26.4)\nRequirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (1.0.7)\nRequirement already satisfied: optax in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (0.2.2)\nRequirement already satisfied: orbax-checkpoint in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (0.5.20)\nRequirement already satisfied: tensorstore in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (0.1.63)\nRequirement already satisfied: rich>=11.1 in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (13.7.0)\nRequirement already satisfied: typing-extensions>=4.2 in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (4.9.0)\nRequirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.10/site-packages (from flax>=0.7.2->tensorflowjs) (6.0.1)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.13->tensorflowjs) (0.2.0)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.13->tensorflowjs) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax>=0.4.13->tensorflowjs) (1.11.4)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (16.0.6)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (69.0.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3,>=2.13.0->tensorflowjs) (2.15.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.2.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (0.42.0)\nRequirement already satisfied: wurlitzer in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests>=1.5.0->tensorflowjs) (3.1.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1->flax>=0.7.2->tensorflowjs) (2.17.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.0.3)\nRequirement already satisfied: chex>=0.1.86 in /opt/conda/lib/python3.10/site-packages (from optax->flax>=0.7.2->tensorflowjs) (0.1.86)\nRequirement already satisfied: etils[epath,epy] in /opt/conda/lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.6.0)\nRequirement already satisfied: nest_asyncio in /opt/conda/lib/python3.10/site-packages (from orbax-checkpoint->flax>=0.7.2->tensorflowjs) (1.5.8)\nINFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\nCollecting tensorstore (from flax>=0.7.2->tensorflowjs)\n  Downloading tensorstore-0.1.62-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.61-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.59-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.58-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.57-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.56-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nINFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n  Downloading tensorstore-0.1.55-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.54-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.53-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.52-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.51-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\nCollecting orbax-checkpoint (from flax>=0.7.2->tensorflowjs)\n  Downloading orbax_checkpoint-0.5.23-py3-none-any.whl.metadata (1.8 kB)\nCollecting tensorstore (from flax>=0.7.2->tensorflowjs)\n  Downloading tensorstore-0.1.50-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.49-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n  Downloading tensorstore-0.1.48-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n  Downloading tensorstore-0.1.47-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n  Downloading tensorstore-0.1.46-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n  Downloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\nCollecting orbax-checkpoint (from flax>=0.7.2->tensorflowjs)\n  Downloading orbax_checkpoint-0.5.22-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.21-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.20-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.19-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.18-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.17-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.16-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.15-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.14-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.13-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.12-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.11-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.10-py3-none-any.whl.metadata (1.8 kB)\n  Downloading orbax_checkpoint-0.5.9-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.8-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.7-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.6-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.5-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.4-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n  Downloading orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests>=1.5.0->tensorflowjs) (2023.4)\nRequirement already satisfied: toolz>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chex>=0.1.86->optax->flax>=0.7.2->tensorflowjs) (0.12.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->tensorflowjs) (0.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (2.1.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (2024.5.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.7.2->tensorflowjs) (3.17.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<3,>=2.13.0->tensorflowjs) (3.2.2)\nDownloading tensorflowjs-4.20.0-py3-none-any.whl (89 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.1/89.1 kB\u001B[0m \u001B[31m3.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m53.0/53.0 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tensorstore-0.1.45-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.5/13.5 MB\u001B[0m \u001B[31m26.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n\u001B[?25hDownloading orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m124.0/124.0 kB\u001B[0m \u001B[31m5.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: tensorstore, packaging, orbax-checkpoint, tensorflowjs\n  Attempting uninstall: tensorstore\n    Found existing installation: tensorstore 0.1.63\n    Uninstalling tensorstore-0.1.63:\n      Successfully uninstalled tensorstore-0.1.63\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orbax-checkpoint\n    Found existing installation: orbax-checkpoint 0.5.20\n    Uninstalling orbax-checkpoint-0.5.20:\n      Successfully uninstalled orbax-checkpoint-0.5.20\n\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001B[0m\u001B[31m\n\u001B[0mSuccessfully installed orbax-checkpoint-0.4.4 packaging-23.2 tensorflowjs-4.20.0 tensorstore-0.1.45\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "import tensorflowjs as tfjs\n\nprint(tfjs.__version__)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:16:08.892818Z",
     "iopub.execute_input": "2024-07-29T02:16:08.893323Z",
     "iopub.status.idle": "2024-07-29T02:16:10.843686Z",
     "shell.execute_reply.started": "2024-07-29T02:16:08.893286Z",
     "shell.execute_reply": "2024-07-29T02:16:10.842421Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "4.20.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**First, we need to save it as .h5 because tf_js converter doesn't support .keras model file\n",
    "\n",
    "Or just save it as .h5 in the first place**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Save the model in HDF5 format\nmodel.save('/kaggle/working/bio_nonbio_model_best.h5', save_format='h5')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-29T02:44:47.809915Z",
     "iopub.execute_input": "2024-07-29T02:44:47.810374Z",
     "iopub.status.idle": "2024-07-29T02:44:48.046800Z",
     "shell.execute_reply.started": "2024-07-29T02:44:47.810339Z",
     "shell.execute_reply": "2024-07-29T02:44:48.045461Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If the conversion doesn't work try from command line with the following commad:\n",
    "\n",
    "!tensorflowjs_converter --input_format=keras /kaggle/working/bio_nonbio_model_best.h5 /kaggle/working/tfjs_model"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Path to the Keras model\nkeras_model_path = \"/kaggle/input/waste-classification-model/tensorflow2/default/1/bio_nonbio_model_best.keras\"\n\n# Destination path for the TensorFlow.js model\ntfjs_target_dir = \"/kaggle/working/bio_nonbio_model_best_tfjs_model\"\n\n# Convert the model\ntfjs.converters.save_keras_model(tf.keras.models.load_model(keras_model_path), tfjs_target_dir)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-28T23:30:28.326856Z",
     "iopub.execute_input": "2024-07-28T23:30:28.327578Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
